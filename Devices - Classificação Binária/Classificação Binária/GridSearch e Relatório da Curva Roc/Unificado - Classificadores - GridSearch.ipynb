{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b5cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn \n",
    "import imblearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, precision_recall_fscore_support, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac3f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignorando avisos\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formatação\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(threshold= 15)\n",
    "np.set_printoptions(precision=3)\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219df0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C_Dados_V5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b5029",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a513bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5029c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ts'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4387d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b15641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f957a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fridge_temperature'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c30eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temp_condition'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad5c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['door_state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sphone_signal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c2f2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['latitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c293a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['longitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b3d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FC1_Read_Input_Register'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee36e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FC2_Read_Discrete_Value'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85112d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FC3_Read_Holding_Register'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FC4_Read_Coil'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0775818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['motion_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca9840",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['light_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dbf280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['current_temperature'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d36a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['thermostat_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d5f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temperature'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43622fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pressure'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5fdf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['humidity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446078e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fede5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ceb271",
   "metadata": {},
   "source": [
    "## Processamento dos Dados\n",
    "#### Dimensionamento (StandardScaler / Padronização)\n",
    "\n",
    "Antes de fazer o preprocessamento : \n",
    "- Dividir o conjunto (evitando o vazamento' de informação durante cada etapa do processo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24907d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015df3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eca70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste sem a feature de TS. \n",
    "df.drop(['ts', 'type'], axis=1, inplace=True)\n",
    "\n",
    "# Substituindo os espaços em branco na coluna 'time'\n",
    "df['time'] = df['time'].str.replace(' ', '')\n",
    "\n",
    "df['hour'] = ''\n",
    "df['minute'] = ''\n",
    "df['second'] = ''\n",
    "\n",
    "df[['hour', 'minute', 'second']] = df['time'].str.split(':', expand=True)\n",
    "\n",
    "df['hour'] = df['hour'].astype(int)\n",
    "df['minute'] = df['minute'].astype(int)\n",
    "df['second'] = df['second'].astype(int)\n",
    "\n",
    "\n",
    "# Criando outras features usando a data (day-month-year)\n",
    "df.date = pd.to_datetime(df.date)\n",
    "df['day'] = df.date.dt.day\n",
    "df['month'] = df.date.dt.month\n",
    "df['year'] = df.date.dt.year\n",
    "\n",
    "df.drop(labels=['date'], inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43465986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excluindo também a coluna 'year', porque ela só contém um valor. \n",
    "df.drop(['year','month', 'time'], axis=1, inplace=True)\n",
    "#Head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cf786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f455280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f16078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as Features do Label\n",
    "y_data = df.label\n",
    "X_data = df.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df02f50",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "O bloco de código a seguir realiza pré-processamento do conjunto de dados, com o objetivo de prepará-lo para treinar um modelo de aprendizado de máquina.\n",
    "\n",
    "A primeira linha define uma lista com o nome das colunas que contêm variáveis categóricas.\n",
    "\n",
    "Em seguida, é criado um objeto `ColumnTransformer` que irá lidar com os dados das colunas categóricas, usando a classe OrdinalEncoder para transformar esses dados em valores numéricos ordinais. O parâmetro **``remainder='passthrough'``** é usado para manter as colunas que não são categóricas inalteradas.\n",
    "\n",
    "Por fim, criamo um objeto `Pipeline` que irá aplicar o pré-processamento aos dados. Ele consiste em dois passos:\n",
    "\n",
    "* O primeiro passo é aplicar o ColumnTransformer criado anteriormente, que irá lidar com as colunas categóricas e manter as outras colunas sem modificação.\n",
    "* O segundo passo é aplicar um StandardScaler para normalizar os valores das colunas numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616dbc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "categorical_features = ['temp_condition', 'door_state', 'sphone_signal', 'light_status', 'thermostat_status', ]\n",
    "cat_handle = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        ('cat', OrdinalEncoder(), categorical_features),\n",
    "                         ], remainder='passthrough')\n",
    "\n",
    "# Juntamos tudo; Lidando com os dados categoricos e em seguida fazendo o standardscaler\n",
    "preprocessor = Pipeline(steps=[\n",
    "    ('categorical', cat_handle), \n",
    "    ('numerical', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eff6f6",
   "metadata": {},
   "source": [
    "## Divisão dos dados\n",
    "\n",
    "Esse código está usando o objeto StratifiedShuffleSplit da biblioteca sklearn.model_selection para dividir um conjunto de dados em conjuntos de treino e teste. A divisão é feita de forma estratificada, ou seja, preservando a proporção de cada classe do conjunto de dados original nos conjuntos de treino e teste.\n",
    "\n",
    "A classe StratifiedShuffleSplit é uma estratégia de validação cruzada que, ao contrário da validação cruzada tradicional, não faz uma partição fixa do conjunto de dados em k conjuntos. Em vez disso, ela faz várias partições aleatórias do conjunto de dados e, em cada uma delas, mantém a proporção de cada classe nos conjuntos de treino e teste. Essa abordagem é útil quando o conjunto de dados é desbalanceado, ou seja, quando algumas classes têm muito mais instâncias do que outras.\n",
    "\n",
    "O objeto StratifiedShuffleSplit é inicializado com três parâmetros:\n",
    "\n",
    "* `n_splits`: número de partições a serem geradas. Neste caso, é gerada apenas uma partição.\n",
    "* `test_size`: proporção do conjunto de dados a ser usada como teste. Neste caso é default, usamos uma proporção de 0.2, o que significa que 20% das instâncias são usadas como teste.\n",
    "*`random_state`: semente para o gerador de números aleatórios. Neste caso, é usada a semente 0.\n",
    "\n",
    "O loop for é usado para iterar sobre a única partição gerada pelo objeto StratifiedShuffleSplit. Em cada iteração, ele recebe os índices das instâncias que serão usadas como treino e teste e cria dois novos conjuntos de dados (*X_train, y_train* e *X_test, y_test*) com essas instâncias. Esses conjuntos de dados são usados posteriormente para treinar e testar um modelo de aprendizado de máquina.\n",
    "\n",
    "**Em resumo, esse código é uma forma de dividir um conjunto de dados em conjuntos de treino e teste de forma estratificada, o que pode ser útil quando o conjunto de dados é desbalanceado.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb46f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, \n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y_data)\n",
    "\n",
    "# Reparar que está sendo usado o X_data e y_data sem passar o transform neles ainda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fad77f6",
   "metadata": {},
   "source": [
    "# Regressão Logística\n",
    "\n",
    "Foi adicionado algumas configurações no modelo de Regressão Logística, como max_iter, solver, C, e penalty. Além disso, o GridSearchCV é utilizado para ajustar nossos parâmetros em uma grade de valores e encontrar a melhor combinação.\n",
    "\n",
    "Existem alguns parâmetros que você pode ajustar para uma regressão logística no scikit-learn. Aqui estão alguns exemplos:\n",
    "\n",
    "* **`penalty`**: Especifica a norma a ser usada na regularização. Pode ser 'L1', 'L2', 'elasticnet' ou 'none'.\n",
    "\n",
    "\n",
    "* **`C`**: Parâmetro de inversão de regularização. Valores menores especificam uma regularização mais forte.\n",
    "\n",
    "\n",
    "* **`solver`**: Algoritmo a ser usado no problema de otimização. Pode ser 'newton-cg', 'lbfgs', 'liblinear', 'sag' ou 'saga'.\n",
    "\n",
    "\n",
    "* **`max_iter`**: Número máximo de iterações para o solucionador convergir.\n",
    "\n",
    "\n",
    "* **`multi_class`**: Especifica o esquema de classificação multiclasse. Pode ser 'ovr' (one-vs-rest) ou 'multinomial'.\n",
    "\n",
    "\n",
    "* **`class_weight`**: Peso atribuído a cada classe. Pode ser 'balanced' ou um dicionário com pesos personalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22679557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# A variavel 'pipeline', contem a etapa de preprocesamento e o modelo, além do feature selection\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessamento', preprocessor),\n",
    "    ('feature_selection', SelectFromModel(estimator=RandomForestClassifier() , max_features=3)),\n",
    "    ('classificador', LogisticRegression())\n",
    "])\n",
    "\n",
    "param_grid_LR = {\n",
    "                'feature_selection__max_features': [1,2,3],\n",
    "                'classificador__penalty': ['l1', 'l2'],\n",
    "                'classificador__C': [0.1, 1.0, 10.0],\n",
    "                'classificador__solver': ['newton-cg', 'saga'],\n",
    "                'classificador__max_iter': [100, 1000],\n",
    "                'classificador__multi_class': ['ovr', 'multinomial'],\n",
    "                'classificador__class_weight': ['balanced']}\n",
    "\n",
    "# Repare que o param_grid é passado o nome do classifier dois underscore \n",
    "# antes do parametro assim: nomeclassificador__parametro. O nome é passado na string do pipeline\n",
    "# no caso deixei 'classificador' mesmo.\n",
    "grid_search_RL = GridSearchCV(pipeline, param_grid=param_grid_LR, cv=5, n_jobs=-1, refit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15b9d51",
   "metadata": {},
   "source": [
    "A função GridSearchCV da biblioteca sklearn.model_selection possui diversos parâmetros que podem ser utilizados para controlar o processo de busca de hiperparâmetros e a validação cruzada. Abaixo estão listados os principais parâmetros:\n",
    "\n",
    "* **`estimator`**: representa o modelo a ser otimizado e deve ser uma instância de um estimador do scikit-learn.\n",
    "\n",
    "\n",
    "* **`param_grid`**: um dicionário que mapeia nomes de parâmetros do modelo para listas de valores a serem explorados durante a busca de hiperparâmetros.\n",
    "\n",
    "\n",
    "* **`scoring`**: uma métrica de avaliação que será utilizada para avaliar o desempenho do modelo. Deve ser uma string que representa o nome da métrica ou uma função que calcula a métrica. Por padrão, é utilizado o score da função score() do estimador.\n",
    "\n",
    "\n",
    "* **`cv`**: número de partições a serem utilizadas na validação cruzada.\n",
    "\n",
    "\n",
    "* **`n_jobs`**: número de trabalhos em paralelo a serem executados. Se n_jobs=-1, todos os processadores disponíveis serão utilizados.\n",
    "\n",
    "\n",
    "* **`verbose`**: nível de verbosidade do output.\n",
    "\n",
    "\n",
    "* **`pre_dispatch`**: número de trabalhos que devem ser despachados para o trabalhador antes que o próximo lote de tarefas seja despachado. O valor padrão é 2 * n_jobs.\n",
    "\n",
    "\n",
    "* **`return_train_score`**: se True, inclui o score de treino para cada combinação de parâmetros no resultado. O valor padrão é False.\n",
    "\n",
    "\n",
    "* **`refit`**: se True, refita o modelo com os melhores parâmetros encontrados usando todos os dados disponíveis. O valor padrão é True.\n",
    "\n",
    "\n",
    "* **`iid`**: se True, assume que as dobras de validação cruzada são independentes e identicamente distribuídas (i.i.d.), o que não é garantido para todos os tipos de dados. O valor padrão é True.\n",
    "\n",
    "\n",
    "* **`error_score`**: valor a ser atribuído ao score caso ocorra algum erro na validação cruzada.\n",
    "\n",
    "\n",
    "* **`return_estimator`**: se True, retorna os estimadores que foram ajustados para cada combinação de parâmetros. O valor padrão é False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f398de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "grid_search_RL.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a2b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo os melhores parâmetros\n",
    "print(grid_search_RL.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0174cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essas métricas são do conjunto de validação (é pra ver como o modelo se comportou) \n",
    "# O std_score é o desvio padrão (O valor tende a ser baixo)\n",
    "# Não é necessário mostrar métricas de valição ou treino. \n",
    "# O que importa é a metrica no TESTE.\n",
    "# O gridsearch faz a validação cruzado k-fold, o cv=5 são 5 folds.\n",
    "index = grid_search_RL.best_index_\n",
    "results = grid_search_RL.cv_results_\n",
    "\n",
    "mean_score = results['mean_test_score'][index]\n",
    "std_score  = results['std_test_score'][index]\n",
    "\n",
    "print(f\"Validation score: {mean_score:.5f} +- {std_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3776d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui é realizada a predição.\n",
    "# O gridsearch possui um paramentro chamado refit \n",
    "#quando eles está true quer dizer que o modelo JÁ É treinado com os melhores parametros, por isso já dou um predict direto\n",
    "\n",
    "y_pred = grid_search_RL.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# Classification Report (Apenas dos dados de teste)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b048d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix de confusão. Apenas do teste\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, \n",
    "                                        display_labels=['Normal', 'Ataque'], \n",
    "                                        #normalize = 'true', values_format='.1%',\n",
    "                                        cmap=plt.cm.Blues, colorbar=False\n",
    "                                        )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ebc1db",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier\n",
    "\n",
    "Existem vários parâmetros que podem ser ajustados para o modelo KNN usando a busca em grade (GridSearchCV). Esses são alguns dos principais parâmetros que podem ser incluídos no dicionário param_grid:\n",
    "\n",
    "* **`n_neighbors`**: Número de vizinhos mais próximos a serem considerados. É um parâmetro obrigatório do modelo KNN. \n",
    "\n",
    "\n",
    "* **`weights`**: Método de ponderação dos vizinhos próximos. Os valores possíveis são \"uniform\" (ponderação uniforme) ou \"distance\" (ponderação pela inversa da distância).\n",
    "\n",
    "\n",
    "* **`algorithm`**: Algoritmo a ser usado para encontrar os vizinhos próximos. Os valores possíveis são \"auto\" (o algoritmo escolhe o mais apropriado com base nos dados), \"ball_tree\" (utiliza uma estrutura de dados de árvore para acelerar a busca) ou \"kd_tree\" (utiliza uma estrutura de dados de árvore k-dimensionais para acelerar a busca).\n",
    "\n",
    "\n",
    "* **`leaf_size`**: Tamanho da folha a ser usado na estrutura de dados da árvore. Isso afeta a velocidade e a memória necessárias para construir a árvore.\n",
    "\n",
    "\n",
    "* **`p`**: Parâmetro de potência a ser usado na métrica de distância de Minkowski. Se p=1, a distância de Manhattan é usada. Se p=2, a distância euclidiana é usada.\n",
    "\n",
    "\n",
    "* **`metric`**: Métrica de distância a ser usada para medir a distância entre os pontos. Os valores possíveis são \"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\" (usado com o parâmetro p) e outras métricas personalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4afc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "pipeline_knn = Pipeline(steps=[\n",
    "    ('preprocessamento', preprocessor),\n",
    "    ('feature_selection', SelectFromModel(estimator=RandomForestClassifier() , max_features=3)),\n",
    "    ('classificador', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "param_grid_KNN = {\n",
    "                'feature_selection__max_features': [1,2,3],\n",
    "                'classificador__n_neighbors': [1, 3, 5, 7, 9],\n",
    "                'classificador__metric': ['euclidean', 'manhatan', 'chebyshev', 'minkowski']}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline_knn, param_grid=param_grid_KNN, cv=5, n_jobs=-1, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff55ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943a46f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo os melhores parâmetros\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4963281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = grid_search.best_index_\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "mean_score = results['mean_test_score'][index]\n",
    "std_score  = results['std_test_score'][index]\n",
    "\n",
    "print(f\"Validation score: {mean_score:.5f} +- {std_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b09f28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix de Confusão (Apenas do teste)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, \n",
    "                                        display_labels=['Normal', 'Ataque'], \n",
    "                                        #normalize = 'true', values_format='.1%',\n",
    "                                        cmap=plt.cm.Blues, colorbar=False\n",
    "                                        )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a4a33b",
   "metadata": {},
   "source": [
    "## PipeLine Gradient Boosting Master\n",
    "\n",
    "* **`learning_rate`**: Taxa de aprendizado do algoritmo.\n",
    "\n",
    "\n",
    "* **`n_estimators`**: Número de estimadores no algoritmo.\n",
    "\n",
    "\n",
    "* **`max_depth`**: Profundidade máxima das árvores de decisão.\n",
    "\n",
    "\n",
    "* **`min_samples_split`**: Número mínimo de amostras necessárias para dividir um nó interno.\n",
    "\n",
    "\n",
    "* **`min_samples_leaf`**: Número mínimo de amostras necessárias em uma folha.\n",
    "\n",
    "\n",
    "* **`max_features`**: Número máximo de recursos considerados para dividir um nó.\n",
    "\n",
    "\n",
    "* **`subsample`**: Fração de amostras usadas para treinar cada árvore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b7df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_gbm = Pipeline(steps=[\n",
    "    ('preprocessamento', preprocessor),\n",
    "    ('feature_selection', SelectFromModel(estimator=RandomForestClassifier() , max_features=3)),\n",
    "    ('classificador', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "param_grid_GBM = {\n",
    "    'feature_selection__max_features': [1,2,3],\n",
    "    'classificador__learning_rate': [0.1, 0.05],\n",
    "    'classificador__n_estimators': [50, 100],\n",
    "    'classificador__max_depth': [2, 3],\n",
    "    'classificador__min_samples_split': [2, 4],\n",
    "    'classificador__min_samples_leaf': [1, 2],\n",
    "    'classificador__max_features': ['auto', 'sqrt'],\n",
    "    'classificador__subsample': [0.8, 1.0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d094648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443de7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo os melhores parâmetros\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc421ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = grid_search.best_index_\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "mean_score = results['mean_test_score'][index]\n",
    "std_score  = results['std_test_score'][index]\n",
    "\n",
    "print(f\"Validation score: {mean_score:.5f} +- {std_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03fe0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba776bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix de Confusão (Apenas do teste)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, \n",
    "                                        display_labels=['Normal', 'Ataque'], \n",
    "                                        #normalize = 'true', values_format='.1%',\n",
    "                                        cmap=plt.cm.Blues, colorbar=False\n",
    "                                        )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be8c8f4",
   "metadata": {},
   "source": [
    "# Nayve Bayes BernoulliNB\n",
    "\n",
    "A função BernoulliNB() tem apenas um hiperparâmetro para ajuste:\n",
    "\n",
    "* `alpha`: parâmetro de suavização Laplace. Quanto maior o valor de alpha, maior é a suavização aplicada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_nb = Pipeline(steps=[\n",
    "    ('preprocessamento', preprocessor),\n",
    "    ('feature_selection', SelectFromModel(estimator=RandomForestClassifier() , max_features=3)),\n",
    "    ('classificador', BernoulliNB())\n",
    "])\n",
    "\n",
    "param_grid_NB = {\n",
    "    'feature_selection__max_features': [1,2,3],\n",
    "    'classificador__alpha': [0.1, 0.5, 1.0]}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline_nb, param_grid=param_grid_NB, cv=5, n_jobs=-1, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba14fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33479492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo os melhores parâmetros\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51607020",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = grid_search.best_index_\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "mean_score = results['mean_test_score'][index]\n",
    "std_score  = results['std_test_score'][index]\n",
    "\n",
    "print(f\"Validation score: {mean_score:.5f} +- {std_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae42651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5398c6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report (Apenas dos dados de teste)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b9ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix de Confusão (Apenas do teste)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, \n",
    "                                        display_labels=['Normal', 'Ataque'], \n",
    "                                        #normalize = 'true', values_format='.1%',\n",
    "                                        cmap=plt.cm.Blues, colorbar=False\n",
    "                                        )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e023e30",
   "metadata": {},
   "source": [
    "# PipeLine Linear Discriminant Analysis\n",
    "\n",
    "Aqui estão os principais parâmetros que podemos ajustar:\n",
    "\n",
    "* **`solver`**: Algoritmo usado para encontrar a solução. Possíveis valores são svd, lsqr ou eigen.\n",
    "\n",
    "\n",
    "* **`shrinkage`**: Parâmetro de encolhimento utilizado para melhorar a estabilidade da estimativa. Possíveis valores são None, auto ou um valor float entre 0 e 1.\n",
    "\n",
    "\n",
    "* **`tol`**: Tolerância para a convergência do algoritmo. Padrão é 1e-4.\n",
    "\n",
    "\n",
    "* **`n_components`**: Número de componentes para manter. O padrão é manter todas as componentes.\n",
    "\n",
    "\n",
    "* **`priors`**: Probabilidades a priori de cada classe. Se None, as probabilidades são ajustadas de acordo com os dados.\n",
    "\n",
    "\n",
    "* **`store_covariance`**: Se verdadeiro, armazena a matriz de covariância empírica de cada classe. Padrão é False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58d4a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lda = Pipeline(steps=[\n",
    "    ('preprocessamento', preprocessor),\n",
    "    ('feature_selection', SelectFromModel(estimator=RandomForestClassifier() , max_features=3)),\n",
    "    ('classificador', LinearDiscriminantAnalysis())\n",
    "])\n",
    "\n",
    "param_grid_LDA = {\n",
    "    'feature_selection__max_features': [1,2,3],\n",
    "    'classificador__solver': ['svd', 'lsqr', 'eigen']}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline_lda, param_grid=param_grid_LDA, cv=5, n_jobs=-1, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c6c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b76e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo os melhores parâmetros\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee736664",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = grid_search.best_index_\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "mean_score = results['mean_test_score'][index]\n",
    "std_score  = results['std_test_score'][index]\n",
    "\n",
    "print(f\"Validation score: {mean_score:.5f} +- {std_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5270749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8053e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report (Apenas dos dados de teste)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20ac842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix de Confusão (Apenas do teste)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, \n",
    "                                        display_labels=['Normal', 'Ataque'], \n",
    "                                        #normalize = 'true', values_format='.1%',\n",
    "                                        cmap=plt.cm.Blues, colorbar=False\n",
    "                                        )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ca675e",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier\n",
    "\n",
    "Aqui estão alguns dos parâmetros mais comuns que podemos incluir no param_grid para o DecisionTreeClassifier:\n",
    "\n",
    "* **`criterion`**: critério de divisão usado na árvore de decisão. As opções são gini ou entropy.\n",
    "\n",
    "\n",
    "* **`max_depth`**: profundidade máxima da árvore de decisão. Um valor mais alto permitirá que a árvore de decisão tenha mais níveis, o que pode levar a uma melhor precisão, mas também pode levar a um maior risco de sobreajuste.\n",
    "\n",
    "\n",
    "* **`min_samples_split`**: o número mínimo de amostras necessárias para dividir um nó. Isso ajuda a evitar divisões que levam a subárvores muito pequenas.\n",
    "\n",
    "\n",
    "* **`min_samples_leaf`**: o número mínimo de amostras necessárias em uma folha. Isso ajuda a evitar folhas que contenham muito poucas amostras.\n",
    "\n",
    "\n",
    "* **`max_features`**: o número máximo de recursos a serem considerados para cada divisão. Isso pode ajudar a reduzir o risco de sobreajuste.\n",
    "\n",
    "\n",
    "* **`class_weight`**: pesos associados a cada classe. Isso pode ser útil para lidar com conjuntos de dados desbalanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3366c3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_dtc = Pipeline(steps=[\n",
    "    ('preprocessamento', preprocessor),\n",
    "    ('feature_selection', SelectFromModel(estimator=RandomForestClassifier() , max_features=3)),\n",
    "    ('classificador', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "param_grid_DTC = {\n",
    "    'feature_selection__max_features': [1,2,3],\n",
    "    'classificador__criterion': ['gini', 'entropy'],\n",
    "    'classificador__max_depth': [2, 4, 6],\n",
    "    'classificador__min_samples_split': [2, 5, 10],\n",
    "    'classificador__min_samples_leaf': [1, 2, 4],\n",
    "    'classificador__max_features': ['sqrt', 'log2'],\n",
    "    'classificador__class_weight': [None, 'balanced']}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline_dtc, param_grid=param_grid_DTC, cv=5, n_jobs=-1, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ee66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6095bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo os melhores parâmetros\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dd28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = grid_search.best_index_\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "mean_score = results['mean_test_score'][index]\n",
    "std_score  = results['std_test_score'][index]\n",
    "\n",
    "print(f\"Validation score: {mean_score:.5f} +- {std_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7170e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540fed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report (Apenas dos dados de teste)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58050e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix de Confusão (Apenas do teste)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, \n",
    "                                        display_labels=['Normal', 'Ataque'], \n",
    "                                        #normalize = 'true', values_format='.1%',\n",
    "                                        cmap=plt.cm.Blues, colorbar=False\n",
    "                                        )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878187c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc68853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a200289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d60500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c919fdf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
